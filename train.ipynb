{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9e4aec7f-e620-4c07-a35e-1d44d1ea9786",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['All', 'Approved', 'NonApproved', 'test_set.csv', 'train_set.csv', 'val_set.csv', 'xlbst.csv']\n",
      "                                           file_name  label parcel_id\n",
      "0   22-0223605_F78EFF88702EA742E0530EEE260AEFC6.jpeg      1   0223605\n",
      "1   22-0223605_F78EFF887030A742E0530EEE260AEFC6.jpeg      1   0223605\n",
      "2   22-0223605_F78EFF88703AA742E0530EEE260AEFC6.jpeg      1   0223605\n",
      "28  22-0225160_F78EFF887012A742E0530EEE260AEFC6.jpeg      1   0225160\n",
      "29  22-0225160_F78EFF887013A742E0530EEE260AEFC6.jpeg      1   0225160\n",
      "30  22-0225160_F78EFF887014A742E0530EEE260AEFC6.jpeg      1   0225160\n",
      "31  22-0225160_F78EFF887015A742E0530EEE260AEFC6.jpeg      1   0225160\n",
      "32  22-0225160_F78EFF887016A742E0530EEE260AEFC6.jpeg      1   0225160\n",
      "33  22-0225160_F78EFF887017A742E0530EEE260AEFC6.jpeg      1   0225160\n",
      "34  22-0225160_F78EFF88701AA742E0530EEE260AEFC6.jpeg      1   0225160\n",
      "35  22-0225160_F78EFF88701BA742E0530EEE260AEFC6.jpeg      1   0225160\n",
      "36  22-0225160_F78EFF88701CA742E0530EEE260AEFC6.jpeg      1   0225160\n",
      "37  22-0225160_F78EFF88701DA742E0530EEE260AEFC6.jpeg      1   0225160\n",
      "38  22-0225160_F78EFF88701EA742E0530EEE260AEFC6.jpeg      1   0225160\n",
      "39  22-0225160_F78EFF88701FA742E0530EEE260AEFC6.jpeg      1   0225160\n",
      "Test set length:\n",
      "15\n",
      "Train set length:\n",
      "65\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "from lightning.pytorch import seed_everything\n",
    "import random\n",
    "\n",
    "import config\n",
    "\n",
    "# Create .csv file\n",
    "\n",
    "\n",
    "def set_all_seeds(seed):\n",
    "    os.environ[\"PL_GLOBAL_SEED\"] = str(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "\n",
    "## Find folder paths\n",
    "\n",
    "base_path = config.BASE_DIR\n",
    "target_dirs = os.listdir(base_path)\n",
    "print(target_dirs)\n",
    "\n",
    "## Create 2 separate df's: one for Approved images, one for NonApproved, containing file_name and label\n",
    "\n",
    "### Assign label = 0 to Approved images\n",
    "approved = pd.DataFrame(\n",
    "    data=os.listdir(os.path.join(base_path, target_dirs[1])), columns=[\"file_name\"]\n",
    ")\n",
    "approved = approved.assign(label=0)\n",
    "\n",
    "### Assign label = 1 to NonApproved images\n",
    "nonapproved = pd.DataFrame(\n",
    "    data=os.listdir(os.path.join(base_path, target_dirs[2])), columns=[\"file_name\"]\n",
    ")\n",
    "nonapproved = nonapproved.assign(label=1)\n",
    "\n",
    "## Merge into 1 df\n",
    "df = pd.concat([approved, nonapproved])\n",
    "\n",
    "## Add parcel_id column containing character 3-10 from file_name column\n",
    "df[\"parcel_id\"] = df[\"file_name\"].str[3:10]\n",
    "\n",
    "## Write .csv\n",
    "df.to_csv(\n",
    "    r\"C:/Users/kaspe/OneDrive - Aarhus Universitet/Skrivebord/BI/4. semester/Data/LBST/Danish Challenge/2023 J#/xlbst.csv\",\n",
    "    sep=\",\",\n",
    "    encoding=\"utf-8\",\n",
    "    index=False,\n",
    ")\n",
    "\n",
    "\n",
    "## Split group by\n",
    "\n",
    "set_all_seeds(config.SEED)\n",
    "\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "\n",
    "splitter = GroupShuffleSplit(test_size=0.20, n_splits=2, random_state=config.SEED)\n",
    "split = splitter.split(df, groups=df.parcel_id)\n",
    "train_inds, test_inds = next(split)\n",
    "\n",
    "train_set = df.iloc[train_inds]\n",
    "test_set = df.iloc[test_inds]\n",
    "\n",
    "\n",
    "print(test_set.to_string())\n",
    "print(\"Test set length:\", len(test_set), \"Train set length:\", len(train_set), sep=\"\\n\")\n",
    "\n",
    "\n",
    "## Split train into 80/20 train/val\n",
    "\n",
    "train_set2 = train_set\n",
    "splitter2 = GroupShuffleSplit(test_size=0.2, n_splits=1, random_state=config.SEED)\n",
    "split2 = splitter2.split(train_set2, groups=train_set2.parcel_id)\n",
    "train_inds2, val_inds = next(split2)\n",
    "\n",
    "train_set2 = train_set.iloc[train_inds2]\n",
    "val_set = train_set.iloc[val_inds]\n",
    "\n",
    "\n",
    "## Save to csv\n",
    "\n",
    "train_set2.to_csv(\n",
    "    r\"C:/Users/kaspe/OneDrive - Aarhus Universitet/Skrivebord/BI/4. semester/Data/LBST/Danish Challenge/2023 J#/train_set.csv\",\n",
    "    sep=\",\",\n",
    "    encoding=\"utf-8\",\n",
    "    index=False,\n",
    ")\n",
    "val_set.to_csv(\n",
    "    r\"C:/Users/kaspe/OneDrive - Aarhus Universitet/Skrivebord/BI/4. semester/Data/LBST/Danish Challenge/2023 J#/val_set.csv\",\n",
    "    sep=\",\",\n",
    "    encoding=\"utf-8\",\n",
    "    index=False,\n",
    ")\n",
    "test_set.to_csv(\n",
    "    r\"C:/Users/kaspe/OneDrive - Aarhus Universitet/Skrivebord/BI/4. semester/Data/LBST/Danish Challenge/2023 J#/test_set.csv\",\n",
    "    sep=\",\",\n",
    "    encoding=\"utf-8\",\n",
    "    index=False,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd844352-810f-4eb3-b7fa-8421e2eea264",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model\n",
    "\n",
    "from model import NN\n",
    "from dataset import CustomDataModule\n",
    "import config\n",
    "from callbacks import MyPrintingCallback, EarlyStopping\n",
    "\n",
    "seed_everything(\n",
    "    42, workers=True\n",
    ")  # By setting workers=True in seed_everything(), Lightning derives unique seeds across all dataloader workers and processes for torch, numpy and stdlib random number generators. When turned on, it ensures that e.g. data augmentations are not repeated across workers.\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    logger = TensorBoardLogger(\"tb_logs\", name=\"my_model\") # tb_logs is the folder, name is the name of the experiment/model\n",
    "    model = NN(\n",
    "        input_size=config.INPUT_SIZE,\n",
    "        num_classes=config.NUM_CLASSES,\n",
    "        learning_rate=config.LEARNING_RATE,\n",
    "    )  # .to(device)\n",
    "    dm = CustomDataModule(\n",
    "        data_dir=config.DATA_DIR,\n",
    "        train_csv=config.TRAIN_CSV,\n",
    "        val_csv=config.VAL_CSV,\n",
    "        test_csv=config.VAL_CSV,\n",
    "        batch_size=config.BATCH_SIZE,\n",
    "        num_workers=config.NUM_WORKERS,\n",
    "    )\n",
    "    trainer = pl.Trainer(\n",
    "        logger=logger, # PyTorch lightning will automatically know what we are logging by looking at our model.py logs\n",
    "        accelerator=config.ACCELERATOR,\n",
    "        devices=config.DEVICES,\n",
    "        min_epochs=config.MIN_EPOCHS,\n",
    "        max_epochs=config.MAX_EPOCHS,\n",
    "        deterministic=config.DETERMINISTIC,\n",
    "        callbacks=[MyPrintingCallback(), EarlyStopping(monitor=\"val_loss\")],\n",
    "    )  # deterministic ensures random seed reproducibility\n",
    "    trainer.fit(model, dm)  # it will automatically know which dataloader to use\n",
    "    trainer.validate(model, dm)\n",
    "    trainer.test(model, dm)\n",
    "\n",
    "# A general place to start is to set num_workers equal to the number of CPU cores on that machine. You can get the number of CPU cores in python using os.cpu_count(), but note that depending on your batch size, you may overflow RAM memory.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "10737ff7-e534-45fb-b7ba-b4256a90d76d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from createCSV import createCSV\n",
    "import config\n",
    "csv = createCSV(\n",
    "        base_dir = config.BASE_DIR,\n",
    "        all_csv = config.ALL_CSV,\n",
    "        train_csv = config.TRAIN_CSV,\n",
    "        val_csv = config.VAL_CSV,\n",
    "        test_csv = config.TEST_CSV,\n",
    "        label_column = config.LABEL_COLUMN,\n",
    "        test_size = config.TEST_SIZE,\n",
    "        seed = config.SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fa2b720e-f295-4440-9b97-72dc9e830d21",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "createCSV.set_all_seeds() takes 1 positional argument but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#csv.set_all_seeds(1)\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mcsv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_all_seeds\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m csv\u001b[38;5;241m.\u001b[39mdf\n",
      "\u001b[1;31mTypeError\u001b[0m: createCSV.set_all_seeds() takes 1 positional argument but 2 were given"
     ]
    }
   ],
   "source": [
    "#csv.set_all_seeds(1)\n",
    "csv.set_all_seeds(5)\n",
    "csv.df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e29fb31a-6f58-49a4-8dbd-de8eaa935d13",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'int' object has no attribute 'seed'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mcreateCSV\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_all_seeds\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSEED\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\LBST\\createCSV.py:29\u001b[0m, in \u001b[0;36mcreateCSV.set_all_seeds\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mset_all_seeds\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m---> 29\u001b[0m     os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPL_GLOBAL_SEED\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mseed\u001b[49m)\n\u001b[0;32m     30\u001b[0m     random\u001b[38;5;241m.\u001b[39mseed(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseed)\n\u001b[0;32m     31\u001b[0m     np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mseed(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseed)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'int' object has no attribute 'seed'"
     ]
    }
   ],
   "source": [
    "createCSV.set_all_seeds(config.SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f3a46bea-0635-4542-854a-a6cd419fb7d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function createCSV.createCSV.df(self)>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "createCSV.df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "03110d93-61db-4cda-aa0d-b6f3f8fa9199",
   "metadata": {},
   "outputs": [],
   "source": [
    "from createCSV import createCSV\n",
    "import config\n",
    "csv = createCSV(\n",
    "        base_dir = config.BASE_DIR,\n",
    "        all_csv = config.ALL_CSV,\n",
    "        train_csv = config.TRAIN_CSV,\n",
    "        val_csv = config.VAL_CSV,\n",
    "        test_csv = config.TEST_CSV,\n",
    "        label_column = config.LABEL_COLUMN,\n",
    "        test_size = config.TEST_SIZE,\n",
    "        seed = config.SEED)\n",
    "csv.set_all_seeds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9285b0e7-933e-4dc5-9ebc-6c889c685dfe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
