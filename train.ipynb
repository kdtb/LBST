{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ab8f0d26-68d7-4a66-b642-726f16c55ffe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[[[ 1.7865,  1.7865,  1.8037,  ...,  2.2489,  2.2489,  2.2489],\n",
       "           [ 1.8550,  1.8550,  1.8379,  ...,  2.2489,  2.2489,  2.2489],\n",
       "           [ 1.8893,  1.8893,  1.8893,  ...,  2.2489,  2.2489,  2.2489],\n",
       "           ...,\n",
       "           [-1.3644, -1.3473, -1.1760,  ..., -1.0733, -0.7993, -0.5424],\n",
       "           [-1.4158, -1.3815, -1.2788,  ..., -1.0904, -0.5767, -0.7479],\n",
       "           [-1.2959, -1.4500, -1.6213,  ..., -1.0219, -0.6965, -0.9534]],\n",
       " \n",
       "          [[ 2.4111,  2.4111,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
       "           [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
       "           [ 2.4111,  2.4111,  2.4111,  ...,  2.4286,  2.4286,  2.4286],\n",
       "           ...,\n",
       "           [-0.9328, -1.0203, -0.9853,  ..., -0.8627, -0.6352, -0.5126],\n",
       "           [-1.0903, -1.0378, -0.9328,  ..., -1.0203, -0.5301, -0.7577],\n",
       "           [-1.0553, -1.0903, -1.1779,  ..., -0.9153, -0.6352, -0.8978]],\n",
       " \n",
       "          [[ 2.5703,  2.5703,  2.5877,  ...,  2.6400,  2.6400,  2.6400],\n",
       "           [ 2.5877,  2.5877,  2.5877,  ...,  2.6400,  2.6400,  2.6400],\n",
       "           [ 2.6051,  2.6051,  2.6051,  ...,  2.6400,  2.6400,  2.6400],\n",
       "           ...,\n",
       "           [-1.1247, -1.1421, -1.0201,  ..., -1.2119, -1.0201, -0.8807],\n",
       "           [-1.1770, -1.0898, -0.9678,  ..., -1.2641, -0.8458, -1.0724],\n",
       "           [-1.0724, -1.1247, -1.1944,  ..., -1.0724, -0.8110, -1.1073]]],\n",
       " \n",
       " \n",
       "         [[[ 0.6734,  0.8447,  0.4851,  ..., -0.0972, -0.9534, -0.6281],\n",
       "           [ 0.3823,  0.4851,  0.5022,  ..., -0.5596, -0.8507, -0.0287],\n",
       "           [ 0.3138,  0.8961,  0.9646,  ..., -0.7137, -0.5253,  0.5707],\n",
       "           ...,\n",
       "           [-0.4054, -0.9192, -1.1247,  ..., -0.0458, -0.1486,  0.0056],\n",
       "           [-0.7137, -0.8678, -0.9192,  ..., -0.8678, -0.8507,  0.1768],\n",
       "           [-0.6109, -0.6452, -0.5938,  ..., -0.3883, -0.4568, -0.6965]],\n",
       " \n",
       "          [[ 0.8529,  1.1331,  1.2031,  ...,  0.0301, -0.6176, -0.3901],\n",
       "           [ 0.4503,  0.6429,  1.0455,  ..., -0.3725, -0.6877, -0.0049],\n",
       "           [ 0.5203,  1.0980,  1.2556,  ..., -0.1625, -0.1800,  0.5203],\n",
       "           ...,\n",
       "           [-0.0749, -0.4426, -0.6527,  ...,  0.5028,  0.4328,  0.6779],\n",
       "           [-0.3200, -0.5126, -0.5651,  ..., -0.5826, -0.5476,  0.6429],\n",
       "           [-0.3375, -0.3550, -0.4601,  ..., -0.3550, -0.2850, -0.3375]],\n",
       " \n",
       "          [[-0.8110, -1.0201, -1.1247,  ..., -0.3055, -1.1596, -1.0027],\n",
       "           [-1.2119, -1.3861, -1.1421,  ..., -0.8110, -1.0724, -0.5670],\n",
       "           [-1.0376, -0.6890, -0.4101,  ..., -0.9853, -1.0027, -0.1835],\n",
       "           ...,\n",
       "           [-0.4973, -1.0724, -1.2816,  ..., -0.7238, -0.8110, -0.8807],\n",
       "           [-1.1247, -1.2990, -1.3339,  ..., -1.4036, -1.2293, -0.7064],\n",
       "           [-1.0724, -1.1247, -1.1421,  ..., -0.7587, -1.0376, -1.2293]]],\n",
       " \n",
       " \n",
       "         [[[-0.0116,  0.2624,  0.6221,  ..., -0.3027, -0.3198, -0.5082],\n",
       "           [-0.0801, -0.0458,  0.1939,  ..., -0.3883, -0.5082, -0.4739],\n",
       "           [-0.0629,  0.0227,  0.1939,  ..., -0.1486, -0.2342, -0.3712],\n",
       "           ...,\n",
       "           [-0.1828, -0.2171, -0.3369,  ..., -1.0219, -0.5253, -0.8678],\n",
       "           [-0.1143, -0.1143, -0.2171,  ..., -0.6623, -0.4568, -0.7822],\n",
       "           [ 0.1939,  0.2282,  0.1768,  ..., -0.4568, -0.5938, -0.8678]],\n",
       " \n",
       "          [[ 0.3452,  0.5378,  0.7829,  ..., -0.1099, -0.1450, -0.4076],\n",
       "           [ 0.2402,  0.2227,  0.3627,  ..., -0.3025, -0.4076, -0.3901],\n",
       "           [ 0.2402,  0.2752,  0.3452,  ..., -0.0574, -0.1800, -0.3375],\n",
       "           ...,\n",
       "           [-0.1450, -0.1625, -0.1625,  ..., -0.4601,  0.0126, -0.3550],\n",
       "           [-0.0924, -0.1450, -0.1450,  ..., -0.2150,  0.0476, -0.2850],\n",
       "           [ 0.0651,  0.0651,  0.1176,  ..., -0.2325, -0.3025, -0.5476]],\n",
       " \n",
       "          [[ 0.0953,  0.5659,  0.9319,  ...,  0.2173,  0.2173, -0.1835],\n",
       "           [ 0.1128,  0.1651,  0.3568,  ..., -0.2184, -0.2532, -0.1661],\n",
       "           [ 0.0431,  0.0779,  0.1476,  ..., -0.1487, -0.1487, -0.1312],\n",
       "           ...,\n",
       "           [-0.5495, -0.5844, -0.7936,  ..., -1.2816, -0.8981, -1.1421],\n",
       "           [-0.5147, -0.5147, -0.6715,  ..., -1.0724, -0.8633, -1.0550],\n",
       "           [-0.2358, -0.1661, -0.3230,  ..., -1.0201, -0.9853, -1.1421]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[ 0.6049,  0.5536,  0.5364,  ...,  0.6221,  0.5022,  0.4679],\n",
       "           [ 0.5536,  0.5193,  0.4851,  ..., -0.1486, -0.3883, -0.3883],\n",
       "           [ 0.5193,  0.5022,  0.4851,  ..., -0.7650, -0.8849, -0.8335],\n",
       "           ...,\n",
       "           [-0.3198, -0.2342, -0.6281,  ..., -0.5424, -0.4397,  0.0398],\n",
       "           [-0.2342,  0.0056, -0.3027,  ..., -0.3883, -0.0801, -0.2684],\n",
       "           [-0.5767, -0.4397, -0.2171,  ..., -0.6281, -0.1828,  0.3994]],\n",
       " \n",
       "          [[ 1.4832,  1.4482,  1.4482,  ...,  1.5007,  1.3606,  1.3081],\n",
       "           [ 1.4657,  1.4132,  1.3957,  ...,  0.5553,  0.2752,  0.2227],\n",
       "           [ 1.4482,  1.4132,  1.3957,  ..., -0.2150, -0.3375, -0.2850],\n",
       "           ...,\n",
       "           [-0.3375, -0.2500, -0.7052,  ..., -0.8102, -0.5651,  0.0301],\n",
       "           [-0.1800, -0.0574, -0.3725,  ..., -0.5301, -0.1975, -0.3025],\n",
       "           [-0.4076, -0.4076, -0.2325,  ..., -0.5301, -0.1625,  0.3277]],\n",
       " \n",
       "          [[ 2.6400,  2.6400,  2.6400,  ...,  2.4483,  2.2740,  2.1694],\n",
       "           [ 2.6400,  2.6400,  2.6400,  ...,  1.2631,  0.9842,  0.9319],\n",
       "           [ 2.6226,  2.6400,  2.6400,  ...,  0.4788,  0.3916,  0.4439],\n",
       "           ...,\n",
       "           [-0.2532, -0.2532, -0.7064,  ..., -0.6193, -0.3927,  0.1825],\n",
       "           [-0.1487, -0.0615, -0.3230,  ..., -0.4275, -0.0790, -0.2184],\n",
       "           [-0.4101, -0.3927, -0.1487,  ..., -0.4450, -0.1312,  0.3568]]],\n",
       " \n",
       " \n",
       "         [[[ 1.7352,  1.7523,  1.8379,  ...,  1.9920,  2.0092,  1.9578],\n",
       "           [ 1.6667,  1.7180,  1.7694,  ...,  1.9407,  1.9578,  1.9235],\n",
       "           [ 1.6324,  1.7009,  1.7009,  ...,  1.9064,  1.9407,  1.9407],\n",
       "           ...,\n",
       "           [ 1.3584,  1.1015,  0.7762,  ..., -0.4568, -1.2103, -1.0048],\n",
       "           [ 0.6221,  0.6734,  0.4679,  ..., -0.2513, -0.9705, -0.9363],\n",
       "           [ 0.6734,  0.3138,  0.3481,  ..., -0.2342, -0.6452, -1.1418]],\n",
       " \n",
       "          [[ 2.0084,  2.0434,  2.0959,  ...,  2.2185,  2.2185,  2.1835],\n",
       "           [ 1.9559,  1.9909,  2.0434,  ...,  2.1835,  2.1835,  2.1660],\n",
       "           [ 1.9209,  1.9734,  1.9734,  ...,  2.1660,  2.1660,  2.1660],\n",
       "           ...,\n",
       "           [ 1.2556,  1.0105,  0.6779,  ..., -0.3375, -0.8803, -0.6527],\n",
       "           [ 0.5553,  0.5903,  0.3277,  ...,  0.0476, -0.6352, -0.3901],\n",
       "           [ 0.5728,  0.3102,  0.3277,  ...,  0.2052, -0.3375, -0.6702]],\n",
       " \n",
       "          [[ 2.6226,  2.6226,  2.6226,  ...,  2.6226,  2.6400,  2.6400],\n",
       "           [ 2.5877,  2.6051,  2.6226,  ...,  2.6226,  2.6226,  2.6226],\n",
       "           [ 2.5703,  2.6051,  2.6051,  ...,  2.6400,  2.6400,  2.6400],\n",
       "           ...,\n",
       "           [ 0.5136,  0.1999, -0.1835,  ..., -0.7413, -1.2816, -1.1421],\n",
       "           [-0.2010, -0.2010, -0.4450,  ..., -0.6367, -1.0724, -1.1247],\n",
       "           [-0.4101, -0.6018, -0.5321,  ..., -0.8633, -0.9853, -1.2293]]],\n",
       " \n",
       " \n",
       "         [[[ 0.5707,  0.5364,  0.5193,  ..., -0.1143, -0.1314, -0.1657],\n",
       "           [ 0.5707,  0.5707,  0.5536,  ..., -0.0972, -0.1314, -0.1486],\n",
       "           [ 0.5878,  0.5878,  0.5707,  ..., -0.0972, -0.0972, -0.1314],\n",
       "           ...,\n",
       "           [-1.4843, -1.3815, -1.4843,  ..., -0.8164, -1.2445, -1.5528],\n",
       "           [-1.4843, -1.5014, -1.4843,  ..., -0.7479, -0.9705, -1.2788],\n",
       "           [-1.3644, -1.3815, -1.3815,  ..., -0.8335, -0.9020, -0.9363]],\n",
       " \n",
       "          [[ 1.6232,  1.5882,  1.5707,  ...,  0.9930,  0.9755,  0.9405],\n",
       "           [ 1.6232,  1.6232,  1.6057,  ...,  1.0105,  0.9755,  0.9580],\n",
       "           [ 1.6408,  1.6408,  1.6232,  ...,  1.0105,  1.0105,  0.9755],\n",
       "           ...,\n",
       "           [-0.9853, -0.9503, -1.1429,  ..., -0.6527, -1.0728, -1.2654],\n",
       "           [-1.0728, -1.1253, -1.1253,  ..., -0.5476, -0.8102, -1.0378],\n",
       "           [-1.1078, -1.0903, -1.0028,  ..., -0.6176, -0.7402, -0.7227]],\n",
       " \n",
       "          [[ 2.5180,  2.4831,  2.4657,  ...,  2.0648,  2.0474,  2.0125],\n",
       "           [ 2.5180,  2.5180,  2.5006,  ...,  2.0823,  2.0474,  2.0300],\n",
       "           [ 2.5354,  2.5354,  2.5180,  ...,  2.0823,  2.0823,  2.0474],\n",
       "           ...,\n",
       "           [-0.6367, -0.5844, -0.7413,  ..., -0.5147, -0.8981, -1.0027],\n",
       "           [-0.6890, -0.7413, -0.7238,  ..., -0.4624, -0.6715, -0.7936],\n",
       "           [-0.7238, -0.7238, -0.6715,  ..., -0.5670, -0.6367, -0.4973]]]]),\n",
       " tensor([1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1])]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import config\n",
    "from customDataModule import CustomDataModule\n",
    "dm = CustomDataModule(\n",
    "        data_dir=config.DATA_DIR,\n",
    "        train_csv=config.TRAIN_CSV,\n",
    "        val_csv=config.VAL_CSV,\n",
    "        test_csv=config.VAL_CSV,\n",
    "        batch_size=config.BATCH_SIZE,\n",
    "        num_workers=config.NUM_WORKERS,\n",
    "    )\n",
    "\n",
    "dm.setup(\"train\") # setup skal instantiates for at kunne lave train_dataloader\n",
    "dm.train_dataloader()\n",
    "\n",
    "train_dataloader = dm.train_dataloader()\n",
    "train_dataloader_iterator = iter(train_dataloader) # Use iter() to generate an iterator for the dataloader\n",
    "data = next(train_dataloader_iterator) # use next() function on the iterator object to get 1st batch of data\n",
    "data\n",
    "#data # \"data will now contain the first batch of data from train_dataloader, \n",
    "     # which may include one or multiple images depending on the batch size. If the batch size is 16, data will have the shape [16, C, H, W], where C, H, and W are the dimensions of the image in channel, height, and width, respectively.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f64209da-e6ac-4d56-af79-601e2a7b3703",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "#import torchvision.transforms.functional as TF\n",
    "import torchvision.transforms as T\n",
    "import torch\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Get first image from batch\n",
    "image_tensor = data[0][1]   # data should have shape 16: [16, C, H, W]\n",
    "print(image_tensor.shape)\n",
    "\n",
    "# define a transform to convert a tensor to PIL image\n",
    "transform = T.ToPILImage()\n",
    "\n",
    "# convert the tensor to PIL image using above transform\n",
    "image_tensor = transform(image_tensor)\n",
    "\n",
    "# display the PIL image\n",
    "\n",
    "image_tensor.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c8777c19-4c8f-48d2-bff3-9b96d4f4540f",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Cannot handle this data type: (1, 1, 224), |u1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\.conda\\envs\\LBST\\lib\\site-packages\\PIL\\Image.py:3080\u001b[0m, in \u001b[0;36mfromarray\u001b[1;34m(obj, mode)\u001b[0m\n\u001b[0;32m   3079\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3080\u001b[0m     mode, rawmode \u001b[38;5;241m=\u001b[39m \u001b[43m_fromarray_typemap\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtypekey\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m   3081\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[1;31mKeyError\u001b[0m: ((1, 1, 224), '|u1')",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 10\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Image\u001b[38;5;241m.\u001b[39mfromarray(tensor)\n\u001b[0;32m      9\u001b[0m tensor \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m---> 10\u001b[0m \u001b[43mtensor_to_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[26], line 7\u001b[0m, in \u001b[0;36mtensor_to_image\u001b[1;34m(tensor)\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m tensor\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m      6\u001b[0m     tensor \u001b[38;5;241m=\u001b[39m tensor[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m----> 7\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mImage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfromarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\.conda\\envs\\LBST\\lib\\site-packages\\PIL\\Image.py:3083\u001b[0m, in \u001b[0;36mfromarray\u001b[1;34m(obj, mode)\u001b[0m\n\u001b[0;32m   3081\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   3082\u001b[0m         msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot handle this data type: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m typekey\n\u001b[1;32m-> 3083\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m   3084\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   3085\u001b[0m     rawmode \u001b[38;5;241m=\u001b[39m mode\n",
      "\u001b[1;31mTypeError\u001b[0m: Cannot handle this data type: (1, 1, 224), |u1"
     ]
    }
   ],
   "source": [
    "def tensor_to_image(tensor):\n",
    "    tensor = tensor*255\n",
    "    tensor = np.array(tensor, dtype=np.uint8)\n",
    "    if np.ndim(tensor)>3:\n",
    "        assert tensor.shape[0] == 1\n",
    "        tensor = tensor[0]\n",
    "    return Image.fromarray(tensor)\n",
    "\n",
    "tensor = data[0][1]\n",
    "tensor_to_image(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "08d4577a-a38b-43f2-a43f-371c414f9fd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function Tensor.size>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0].size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d7d70776-fcbe-42cb-8ef1-8e2c28f03ab7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 3, 224, 224])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d07f11fc-9ec9-4021-8090-645437ab580e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c4a349ff-d953-4753-a830-0fa3085043ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 224, 224])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_tensor = data[0][1]   # data should have shape 16: [16, C, H, W]\n",
    "image_tensor.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7e25e430-9f58-42fc-bd58-bcb12ccae227",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_tensor = data[0]\n",
    "\n",
    "#new_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "89c9a11d-1c5a-4b18-819c-95645298b978",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 150528 into shape (244,244,3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 22\u001b[0m\n\u001b[0;32m      9\u001b[0m image_tensor \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m1\u001b[39m]   \u001b[38;5;66;03m# data should have shape 16: [16, C, H, W]\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m#print(image_tensor.shape)\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Remove batch dimension\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# display the PIL image\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m#img.show()\u001b[39;00m\n\u001b[1;32m---> 22\u001b[0m pil_image \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mfromarray(\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_tensor\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muint8\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m244\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m244\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m#print(image_tensor.shape)\u001b[39;00m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m#image_tensor = np.asarray(image_tensor)\u001b[39;00m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m#image_tensor = Image.fromarray((np.asarray(image_tensor)*255).astype(np.uint8))\u001b[39;00m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m# Convert tensor to PIL-image\u001b[39;00m\n\u001b[0;32m     28\u001b[0m pil_image \u001b[38;5;241m=\u001b[39m TF\u001b[38;5;241m.\u001b[39mto_pil_image(pil_image)\n",
      "\u001b[1;31mValueError\u001b[0m: cannot reshape array of size 150528 into shape (244,244,3)"
     ]
    }
   ],
   "source": [
    "import torchvision.transforms.functional as TF\n",
    "import torchvision.transforms as T\n",
    "import torch\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Get first image from batch\n",
    "image_tensor = data[0][1]   # data should have shape 16: [16, C, H, W]\n",
    "#print(image_tensor.shape)\n",
    "# Remove batch dimension\n",
    "\n",
    "# define a transform to convert a tensor to PIL image\n",
    "#transform = T.ToPILImage()\n",
    "\n",
    "# convert the tensor to PIL image using above transform\n",
    "#img = transform(image_tensor)\n",
    "\n",
    "# display the PIL image\n",
    "#img.show()\n",
    "\n",
    "pil_image = Image.fromarray(np.asarray(image_tensor).astype(np.uint8).reshape((244,244,3)))\n",
    "\n",
    "#print(image_tensor.shape)\n",
    "#image_tensor = np.asarray(image_tensor)\n",
    "#image_tensor = Image.fromarray((np.asarray(image_tensor)*255).astype(np.uint8))\n",
    "# Convert tensor to PIL-image\n",
    "pil_image = TF.to_pil_image(pil_image)\n",
    "\n",
    "# Show image\n",
    "pil_image.show()\n",
    "#image_tensor.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "11555517-7c41-4bce-8417-f24609e07b43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 3, 224, 224])"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_tensor = data[0]\n",
    "torch.squeeze(image_tensor, 2)\n",
    "image_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "650a982d-2370-4a52-807f-024c53fa2486",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2bec5a79-dd10-45c4-a9d9-9783aa288ccd",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "axes don't match array",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[35], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m billede \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m      3\u001b[0m billede \u001b[38;5;241m=\u001b[39m billede\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m----> 4\u001b[0m billede \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtranspose\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbillede\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m billede \u001b[38;5;241m=\u001b[39m (billede \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m255\u001b[39m)\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39muint8)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n",
      "File \u001b[1;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mtranspose\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[1;32m~\\.conda\\envs\\LBST\\lib\\site-packages\\numpy\\core\\fromnumeric.py:660\u001b[0m, in \u001b[0;36mtranspose\u001b[1;34m(a, axes)\u001b[0m\n\u001b[0;32m    601\u001b[0m \u001b[38;5;129m@array_function_dispatch\u001b[39m(_transpose_dispatcher)\n\u001b[0;32m    602\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtranspose\u001b[39m(a, axes\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    603\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    604\u001b[0m \u001b[38;5;124;03m    Reverse or permute the axes of an array; returns the modified array.\u001b[39;00m\n\u001b[0;32m    605\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    658\u001b[0m \n\u001b[0;32m    659\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 660\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_wrapfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtranspose\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxes\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\.conda\\envs\\LBST\\lib\\site-packages\\numpy\\core\\fromnumeric.py:57\u001b[0m, in \u001b[0;36m_wrapfunc\u001b[1;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[0;32m     54\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _wrapit(obj, method, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 57\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m bound(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m     59\u001b[0m     \u001b[38;5;66;03m# A TypeError occurs if the object does have such a method in its\u001b[39;00m\n\u001b[0;32m     60\u001b[0m     \u001b[38;5;66;03m# class, but its signature is not identical to that of NumPy's. This\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     64\u001b[0m     \u001b[38;5;66;03m# Call _wrapit from within the except clause to ensure a potential\u001b[39;00m\n\u001b[0;32m     65\u001b[0m     \u001b[38;5;66;03m# exception has a traceback chain.\u001b[39;00m\n\u001b[0;32m     66\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _wrapit(obj, method, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n",
      "\u001b[1;31mValueError\u001b[0m: axes don't match array"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "billede = data[0]\n",
    "billede = billede.cpu().numpy()\n",
    "billede = np.transpose(billede, (1, 2, 0))\n",
    "billede = (billede * 255).astype(np.uint8)\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(billede)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2ddd5f7f-9d5a-407b-9eab-2840b745deb8",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "axes don't match array",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 19\u001b[0m\n\u001b[0;32m     16\u001b[0m     plt\u001b[38;5;241m.\u001b[39mshow()\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# Viser det første billede i batchen\u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m \u001b[43mshow_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[28], line 9\u001b[0m, in \u001b[0;36mshow_image\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m      6\u001b[0m img \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Omarrangerer dimensionerne til [C, H, W]\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m img \u001b[38;5;241m=\u001b[39m \u001b[43mimg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtranspose\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Skalerer pixelværdierne til at være mellem 0 og 1\u001b[39;00m\n\u001b[0;32m     12\u001b[0m img \u001b[38;5;241m=\u001b[39m img \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m0.5\u001b[39m\n",
      "\u001b[1;31mValueError\u001b[0m: axes don't match array"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Definerer en funktion til at vise et billede fra data\n",
    "def show_image(data):\n",
    "    # Omgør data fra tensor til en NumPy array og flyt den til CPU'en\n",
    "    img = data.cpu().numpy()\n",
    "\n",
    "    # Omarrangerer dimensionerne til [C, H, W]\n",
    "    img = img.transpose(1, 2, 0)\n",
    "\n",
    "    # Skalerer pixelværdierne til at være mellem 0 og 1\n",
    "    img = img / 2 + 0.5\n",
    "\n",
    "    # Viser billedet\n",
    "    plt.imshow(img)\n",
    "    plt.show()\n",
    "\n",
    "# Viser det første billede i batchen\n",
    "show_image(data[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96e2b974-4c1c-4309-84f2-9e00295245f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "16246a08-844e-44f5-8f3e-dcb72a887107",
   "metadata": {},
   "outputs": [],
   "source": [
    "dm.setup(stage=\"fit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "331b85b6-89e9-4aba-8602-5b6496e59f2f",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'method' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[44], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m dm\u001b[38;5;241m.\u001b[39mtrain_dataloader:\n\u001b[0;32m      2\u001b[0m     inputs, targets \u001b[38;5;241m=\u001b[39m batch\n",
      "\u001b[1;31mTypeError\u001b[0m: 'method' object is not iterable"
     ]
    }
   ],
   "source": [
    "for batch in train_dataloader:\n",
    "    inputs, targets = batch\n",
    "\n",
    "#train_dataloader = dm.train_dataloader()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "03110d93-61db-4cda-aa0d-b6f3f8fa9199",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['All', 'Approved', 'NonApproved', 'test_set.csv', 'train_set.csv', 'val_set.csv', 'xlbst.csv']\n",
      "                                           file_name  label parcel_id\n",
      "0   22-0223605_F78EFF88702EA742E0530EEE260AEFC6.jpeg      1   0223605\n",
      "1   22-0223605_F78EFF887030A742E0530EEE260AEFC6.jpeg      1   0223605\n",
      "2   22-0223605_F78EFF88703AA742E0530EEE260AEFC6.jpeg      1   0223605\n",
      "28  22-0225160_F78EFF887012A742E0530EEE260AEFC6.jpeg      1   0225160\n",
      "29  22-0225160_F78EFF887013A742E0530EEE260AEFC6.jpeg      1   0225160\n",
      "30  22-0225160_F78EFF887014A742E0530EEE260AEFC6.jpeg      1   0225160\n",
      "31  22-0225160_F78EFF887015A742E0530EEE260AEFC6.jpeg      1   0225160\n",
      "32  22-0225160_F78EFF887016A742E0530EEE260AEFC6.jpeg      1   0225160\n",
      "33  22-0225160_F78EFF887017A742E0530EEE260AEFC6.jpeg      1   0225160\n",
      "34  22-0225160_F78EFF88701AA742E0530EEE260AEFC6.jpeg      1   0225160\n",
      "35  22-0225160_F78EFF88701BA742E0530EEE260AEFC6.jpeg      1   0225160\n",
      "36  22-0225160_F78EFF88701CA742E0530EEE260AEFC6.jpeg      1   0225160\n",
      "37  22-0225160_F78EFF88701DA742E0530EEE260AEFC6.jpeg      1   0225160\n",
      "38  22-0225160_F78EFF88701EA742E0530EEE260AEFC6.jpeg      1   0225160\n",
      "39  22-0225160_F78EFF88701FA742E0530EEE260AEFC6.jpeg      1   0225160\n",
      "Test set length:\n",
      "15\n",
      "Train set length:\n",
      "65\n"
     ]
    }
   ],
   "source": [
    "from createCSV import createCSV\n",
    "import config\n",
    "csv = createCSV(\n",
    "        base_dir = config.BASE_DIR,\n",
    "        all_csv = config.ALL_CSV,\n",
    "        train_csv = config.TRAIN_CSV,\n",
    "        val_csv = config.VAL_CSV,\n",
    "        test_csv = config.TEST_CSV,\n",
    "        label_column = config.LABEL_COLUMN,\n",
    "        test_size = config.TEST_SIZE,\n",
    "        seed = config.SEED)\n",
    "csv.set_all_seeds()\n",
    "csv.df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cd844352-810f-4eb3-b7fa-8421e2eea264",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name     | Type               | Params\n",
      "------------------------------------------------\n",
      "0 | fc1      | Linear             | 7.5 M \n",
      "1 | fc2      | Linear             | 102   \n",
      "2 | loss_fn  | CrossEntropyLoss   | 0     \n",
      "3 | accuracy | MulticlassAccuracy | 0     \n",
      "4 | f1_score | MulticlassF1Score  | 0     \n",
      "------------------------------------------------\n",
      "7.5 M     Trainable params\n",
      "0         Non-trainable params\n",
      "7.5 M     Total params\n",
      "30.106    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kaspe\\.conda\\envs\\LBST\\lib\\site-packages\\pytorch_lightning\\loops\\fit_loop.py:280: PossibleUserWarning: The number of training batches (4) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to train!\n",
      "Epoch 0: 100%|██████████| 4/4 [00:06<00:00,  1.53s/it, v_num=6]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 0: 100%|██████████| 4/4 [00:11<00:00,  2.90s/it, v_num=6].32it/s]\u001b[A\n",
      "Epoch 1: 100%|██████████| 4/4 [00:04<00:00,  1.03s/it, v_num=6, train_loss=10.70, train_accuracy=0.462, train_f1_score=0.462]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1: 100%|██████████| 4/4 [00:09<00:00,  2.38s/it, v_num=6, train_loss=10.70, train_accuracy=0.462, train_f1_score=0.462]\n",
      "Epoch 2: 100%|██████████| 4/4 [00:05<00:00,  1.48s/it, v_num=6, train_loss=9.630, train_accuracy=0.731, train_f1_score=0.731]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 2: 100%|██████████| 4/4 [00:11<00:00,  2.80s/it, v_num=6, train_loss=9.630, train_accuracy=0.731, train_f1_score=0.731]\n",
      "Epoch 3: 100%|██████████| 4/4 [00:06<00:00,  1.50s/it, v_num=6, train_loss=8.070, train_accuracy=0.865, train_f1_score=0.865]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 3: 100%|██████████| 4/4 [00:11<00:00,  2.86s/it, v_num=6, train_loss=8.070, train_accuracy=0.865, train_f1_score=0.865]\n",
      "Epoch 4: 100%|██████████| 4/4 [00:05<00:00,  1.49s/it, v_num=6, train_loss=1.210, train_accuracy=0.942, train_f1_score=0.942]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 4: 100%|██████████| 4/4 [00:09<00:00,  2.35s/it, v_num=6, train_loss=1.210, train_accuracy=0.942, train_f1_score=0.942]\n",
      "Epoch 4: 100%|██████████| 4/4 [00:09<00:00,  2.35s/it, v_num=6, train_loss=12.60, train_accuracy=0.827, train_f1_score=0.827]Training is done!\n",
      "Epoch 4: 100%|██████████| 4/4 [00:09<00:00,  2.41s/it, v_num=6, train_loss=12.60, train_accuracy=0.827, train_f1_score=0.827]\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 91.16it/s] \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     47.49898147583008     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    47.49898147583008    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 83.77it/s] \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     47.49898147583008     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    47.49898147583008    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Train model\n",
    "\n",
    "from model import NN\n",
    "from customDataModule import CustomDataModule\n",
    "import config\n",
    "from callbacks import MyPrintingCallback, EarlyStopping\n",
    "import pytorch_lightning as pl\n",
    "from lightning.pytorch.loggers import TensorBoardLogger\n",
    "from lightning.pytorch import seed_everything\n",
    "\n",
    "seed_everything(\n",
    "    42, workers=True\n",
    ")  # By setting workers=True in seed_everything(), Lightning derives unique seeds across all dataloader workers and processes for torch, numpy and stdlib random number generators. When turned on, it ensures that e.g. data augmentations are not repeated across workers.\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    logger = TensorBoardLogger(\"tb_logs\", name=\"my_model\") # tb_logs is the folder, name is the name of the experiment/model\n",
    "    model = NN(\n",
    "        input_size=config.INPUT_SIZE,\n",
    "        num_classes=config.NUM_CLASSES,\n",
    "        learning_rate=config.LEARNING_RATE,\n",
    "    )  # .to(device)\n",
    "    dm = CustomDataModule(\n",
    "        data_dir=config.DATA_DIR,\n",
    "        train_csv=config.TRAIN_CSV,\n",
    "        val_csv=config.VAL_CSV,\n",
    "        test_csv=config.VAL_CSV,\n",
    "        batch_size=config.BATCH_SIZE,\n",
    "        num_workers=config.NUM_WORKERS,\n",
    "    )\n",
    "    trainer = pl.Trainer(\n",
    "        logger=logger, # PyTorch lightning will automatically know what we are logging by looking at our model.py logs\n",
    "        accelerator=config.ACCELERATOR,\n",
    "        devices=config.DEVICES,\n",
    "        min_epochs=config.MIN_EPOCHS,\n",
    "        max_epochs=config.MAX_EPOCHS,\n",
    "        deterministic=config.DETERMINISTIC,\n",
    "        callbacks=[MyPrintingCallback(), EarlyStopping(monitor=\"val_loss\")],\n",
    "    )  # deterministic ensures random seed reproducibility\n",
    "    trainer.fit(model, dm)  # it will automatically know which dataloader to use\n",
    "    trainer.validate(model, dm)\n",
    "    trainer.test(model, dm)\n",
    "\n",
    "# A general place to start is to set num_workers equal to the number of CPU cores on that machine. You can get the number of CPU cores in python using os.cpu_count(), but note that depending on your batch size, you may overflow RAM memory.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9285b0e7-933e-4dc5-9ebc-6c889c685dfe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
