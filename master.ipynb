{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e4d8b89a-750f-4c30-b4eb-119ff4070c05",
   "metadata": {},
   "source": [
    "# Data preparation (customDataset.py)\n",
    "\n",
    "https://www.learnpytorch.io/04_pytorch_custom_datasets/#what-is-a-custom-dataset\n",
    "https://github.com/mrdbourke/pytorch-deep-learning/blob/main/extras/04_custom_data_creation.ipynb\n",
    "\n",
    "Build custom dataset\n",
    "\n",
    "- Organize into folders\n",
    "- Turn into tensors\n",
    "\n",
    "Image classification format contains separate classes of images in seperate directories titled with a particular class name.\n",
    "\n",
    "The format we aim for:\n",
    "\n",
    "LBST/ <- overall dataset folder\n",
    "    train/ <- training images\n",
    "        Approved/ <- class name as folder name\n",
    "            Parcel-1\n",
    "                image01.jpeg\n",
    "                image02.jpeg\n",
    "                ...\n",
    "            Parcel-2\n",
    "                image-05.jpeg\n",
    "                image-06.jpeg\n",
    "                ...\n",
    "        Not-Approved/\n",
    "            Parcel-3\n",
    "                image07.jpeg\n",
    "                image08.jpeg\n",
    "                ...\n",
    "            Parcel-4\n",
    "                image-09.jpeg\n",
    "                image-10.jpeg\n",
    "                ...\n",
    "    test/ <- testing images\n",
    "        Approved/ <- class name as folder name\n",
    "            Parcel-5\n",
    "                image11.jpeg\n",
    "                image12.jpeg\n",
    "                ...\n",
    "            Parcel-6\n",
    "                image-13.jpeg\n",
    "                image-14.jpeg\n",
    "                ...\n",
    "        Not-Approved/\n",
    "            Parcel-7\n",
    "                image15.jpeg\n",
    "                image16.jpeg\n",
    "                ...\n",
    "            Parcel-8\n",
    "                image-17.jpeg\n",
    "                image-18.jpeg\n",
    "                ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "dffa8aa4-e782-4cfa-9810-844b331a29eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Approved', 'NonApproved']\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Find folder paths\n",
    "\n",
    "base_path = r\"C:/Users/kaspe/OneDrive - Aarhus Universitet/Skrivebord/BI/4. semester/Data/LBST/Danish Challenge/2023 J#/\"\n",
    "target_dirs = os.listdir(base_path)\n",
    "print(target_dirs)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "722ceadd-f8f8-4a72-940c-c193cbce987c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                           file_name  label parcel_id\n",
      "0   22-0223360_F796528C3F8CECCDE0530EEE260A12DE.jpeg      0   0223360\n",
      "1   22-0223360_F796528C3F8DECCDE0530EEE260A12DE.jpeg      0   0223360\n",
      "2   22-0223360_F796528C3F8EECCDE0530EEE260A12DE.jpeg      0   0223360\n",
      "3   22-0223360_F796528C40F1ECCDE0530EEE260A12DE.jpeg      0   0223360\n",
      "4   22-0223360_F796528C40F2ECCDE0530EEE260A12DE.jpeg      0   0223360\n",
      "..                                               ...    ...       ...\n",
      "35  22-0225160_F78EFF88701BA742E0530EEE260AEFC6.jpeg      1   0225160\n",
      "36  22-0225160_F78EFF88701CA742E0530EEE260AEFC6.jpeg      1   0225160\n",
      "37  22-0225160_F78EFF88701DA742E0530EEE260AEFC6.jpeg      1   0225160\n",
      "38  22-0225160_F78EFF88701EA742E0530EEE260AEFC6.jpeg      1   0225160\n",
      "39  22-0225160_F78EFF88701FA742E0530EEE260AEFC6.jpeg      1   0225160\n",
      "\n",
      "[80 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# Create 2 separate df's: one for Approved images, one for NonApproved, containing file_name and label\n",
    "\n",
    "# Assign label = 0 to Approved images\n",
    "approved = pd.DataFrame(data = os.listdir(os.path.join(base_path, target_dirs[0])), columns = ['file_name'])\n",
    "approved = approved.assign(label = 0)\n",
    "\n",
    "# Assign label = 1 to NonApproved images\n",
    "nonapproved = pd.DataFrame(data = os.listdir(os.path.join(base_path, target_dirs[1])), columns = ['file_name'])\n",
    "nonapproved = nonapproved.assign(label = 1)\n",
    "\n",
    "# Merge into 1 df\n",
    "df = pd.concat([approved, nonapproved])\n",
    "\n",
    "# Add parcel_id column containing character 3-10 from file_name column\n",
    "df['parcel_id'] = df['file_name'].str[3:10]\n",
    "print(df)\n",
    "\n",
    "# Write .csv\n",
    "df.to_csv(r'C:/Users/kaspe/OneDrive - Aarhus Universitet/Skrivebord/BI/4. semester/Data/LBST/Danish Challenge/2023 J#/xlbst.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c285f077-db80-4f91-8e0d-1bd59f68ff89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df.assign(parcel_id = np.nan)\n",
    "#df.to_excel(r'C:/Users/kaspe/OneDrive - Aarhus Universitet/Skrivebord/BI/4. semester/Data/LBST/Danish Challenge/2023 J#/Courses.xlsx')\n",
    "\n",
    "#path = [\"C:/Users/kaspe/OneDrive - Aarhus Universitet/Skrivebord/BI/4. semester/Data/LBST/Danish Challenge/2023 J#/Approved\", \"C:/Users/kaspe/OneDrive - Aarhus Universitet/Skrivebord/BI/4. semester/Data/LBST/Danish Challenge/2023 J#/NonApproved\"]\n",
    "#for i in path:\n",
    "#    for filename in os.listdir(i):\n",
    "#        with open(os.path.join(i, filename), 'r') as filedata:\n",
    "#            string = \"\".join(filedata.read().split())\n",
    "\n",
    "\n",
    "#dataframe = pd.DataFrame(columns = ['file_name', 'parcel_id', 'class'])\n",
    "#dataframe.info()\n",
    "\n",
    "# Open a file\n",
    "\n",
    "#df[['class'], ['parcel_id']] = np.nan\n",
    "\n",
    "\n",
    "#for i, j in (range(Approved), range(NonApproved)):\n",
    "    \n",
    "    \n",
    "#files1.extend(files2)\n",
    "#print(df)\n",
    "\n",
    "#dataframe[0][0] = files1[0]\n",
    "\n",
    "#len(df)\n",
    "\n",
    "\n",
    "\n",
    "#new_path = []\n",
    "#for i in base_dirs:\n",
    "#    new_path[i] = os.path.join(base_path, base_dirs[i])\n",
    "\n",
    "\n",
    "#print(new_path)\n",
    "\n",
    "#for i in base_dirs:    \n",
    "#    print(os.path.join(base_path, i))\n",
    "\n",
    "    \n",
    "    #dirs = os.listdir(path)\n",
    "#    name1label = {}\n",
    "#    for file in dirs:\n",
    "#       print(file)\n",
    "#       name1label[file] = 0 #len(name2label.keys())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#path = \"C:/Users/kaspe/OneDrive - Aarhus Universitet/Skrivebord/BI/4. semester/Data/LBST/Danish Challenge/2023 J#/Approved\"\n",
    "#dirs = os.listdir( path )\n",
    "\n",
    "# This would print all the files and directories\n",
    "#name2label = {}\n",
    "#for file in dirs:\n",
    "#   print(file)\n",
    "#   name2label[file] = 0 #len(name2label.keys())\n",
    "\n",
    "#name2label\n",
    "\n",
    "\n",
    "#for key, value in inputdict.items():\n",
    "    # do something with value\n",
    "#    inputdict[key] = newvalue\n",
    "\n",
    "\n",
    "# Data preprocessing: make .csv file containing file-path (xxx.jpeg), parcel-ID, and class\n",
    "\n",
    "\n",
    "#import os\n",
    "\n",
    "\n",
    "# Open a file\n",
    "#path = f'C:\\Users\\kaspe\\OneDrive - Aarhus Universitet\\Skrivebord\\BI\\4. semester\\Data\\LBST\\Danish Challenge\\2023 J#\\Approved'\n",
    "#dirs = os.listdir( path )\n",
    "\n",
    "# This would print all the files and directories\n",
    "#for file in dirs:\n",
    "#   print(file)\n",
    "\n",
    "\n",
    "#load_csv(r'C:\\Users\\kaspe\\OneDrive - Aarhus Universitet\\Skrivebord\\BI\\4. semester\\Data\\LBST\\Danish Challenge\\2023 J#', label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aefddb9f-a164-4d52-9d8f-289feeb97fa9",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'LBSTDataset' from 'customDataset' (C:\\Users\\kaspe\\LBST\\customDataset.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 11\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorchvision\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DataLoader\n\u001b[1;32m---> 11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcustomDataset\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LBSTDataset\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Load data\u001b[39;00m\n\u001b[0;32m     15\u001b[0m dataset \u001b[38;5;241m=\u001b[39m LBSTDataset(csv_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m, root_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     16\u001b[0m                       transform \u001b[38;5;241m=\u001b[39m transforms\u001b[38;5;241m.\u001b[39mToTensor())\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'LBSTDataset' from 'customDataset' (C:\\Users\\kaspe\\LBST\\customDataset.py)"
     ]
    }
   ],
   "source": [
    "# https://www.youtube.com/watch?v=ZoZHd0Zm3RY&ab_channel=AladdinPersson\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "from customDataset import LBSTDataset\n",
    "\n",
    "# Load data: From images to tensor\n",
    "\n",
    "dataset = LBSTDataset(csv_file = '', root_dir = '',\n",
    "                      transform = transforms.ToTensor())\n",
    "\n",
    "# Split data properly without information leak\n",
    "\n",
    "train_set, test_set = torch.utils.data.random_split(dataset, [20000,5000])\n",
    "\n",
    "train_loader = DataLoader(dataset = train_set, batch_size = batch_size, shuffle = True)\n",
    "test_loader = DataLoader(dataset = test_set, batch_size = batch_size, shuffle = True)\n",
    "\n",
    "# Model\n",
    "\n",
    "# Rest of code found: https://www.youtube.com/watch?v=ZoZHd0Zm3RY&ab_channel=AladdinPersson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b90c6f5b-bba8-40f8-9fb7-74477a9ae88e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b56d272e-9538-45dc-8119-3ae440978ccb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cfc61b1-209c-486f-b879-420fad403557",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e71e86-1e0a-4c7d-bbaf-6d05c6789f6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68726414-4cd2-4875-80b5-79bd34d17e06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f917a7-2147-4233-a84e-552cf66655b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d4cfbc8-cc06-4a0e-90e6-f0d0f904924e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77c4db5f-347e-4292-93f8-2d1b22b7afbb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c66518f-e1f3-4167-896f-e9a566e68684",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e7300595",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "92fedcb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\kaspe'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88f00b6d",
   "metadata": {},
   "source": [
    "# data_loader.py\n",
    "specifies how the data should be fed to the network: LightningDataModule\n",
    "\n",
    "In short, data preparation has 4 steps:\n",
    "\n",
    "- Download images\n",
    "- Image transforms (these are highly subjective).\n",
    "- Generate training, validation and test dataset splits.\n",
    "- Wrap each dataset split in a DataLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3fbf82a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://lightning.ai/docs/pytorch/latest/data/datamodule.html\n",
    "\n",
    "import lightning.pytorch as pl\n",
    "from torch.utils.data import random_split, DataLoader\n",
    "\n",
    "# Note - you must have torchvision installed for this example\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision import transforms\n",
    "\n",
    "\n",
    "class MNISTDataModule(pl.LightningDataModule):\n",
    "    def __init__(self, data_dir: str = \"./\"):\n",
    "        super().__init__()\n",
    "        self.data_dir = data_dir\n",
    "        self.transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])\n",
    "\n",
    "    def prepare_data(self):\n",
    "        # download\n",
    "        MNIST(self.data_dir, train=True, download=True)\n",
    "        MNIST(self.data_dir, train=False, download=True)\n",
    "\n",
    "    def setup(self, stage: str):\n",
    "        # Assign train/val datasets for use in dataloaders\n",
    "        if stage == \"fit\":\n",
    "            mnist_full = MNIST(self.data_dir, train=True, transform=self.transform)\n",
    "            self.mnist_train, self.mnist_val = random_split(mnist_full, [55000, 5000])\n",
    "\n",
    "        # Assign test dataset for use in dataloader(s)\n",
    "        if stage == \"test\":\n",
    "            self.mnist_test = MNIST(self.data_dir, train=False, transform=self.transform)\n",
    "\n",
    "        if stage == \"predict\":\n",
    "            self.mnist_predict = MNIST(self.data_dir, train=False, transform=self.transform)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.mnist_train, batch_size=32)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.mnist_val, batch_size=32)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.mnist_test, batch_size=32)\n",
    "\n",
    "    def predict_dataloader(self):\n",
    "        return DataLoader(self.mnist_predict, batch_size=32)\n",
    "\n",
    "data_module = MNISTDataModule()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceb11905",
   "metadata": {},
   "source": [
    "# model.py\n",
    "specifies the neural network architecture, the loss function and evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1a969db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import pytorch_lightning as pl\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torch.nn import functional as F\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision import datasets, transforms\n",
    "import os\n",
    "\n",
    "class LightningMNISTClassifier(pl.LightningModule):\n",
    "\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "\n",
    "    # mnist images are (1, 28, 28) (channels, width, height) \n",
    "    self.layer_1 = torch.nn.Linear(28 * 28, 128)\n",
    "    self.layer_2 = torch.nn.Linear(128, 256)\n",
    "    self.layer_3 = torch.nn.Linear(256, 10)\n",
    "\n",
    "  def forward(self, x):\n",
    "      batch_size, channels, width, height = x.size()\n",
    "\n",
    "      # (b, 1, 28, 28) -> (b, 1*28*28)\n",
    "      x = x.view(batch_size, -1)\n",
    "\n",
    "      # layer 1 (b, 1*28*28) -> (b, 128)\n",
    "      x = self.layer_1(x)\n",
    "      x = torch.relu(x)\n",
    "\n",
    "      # layer 2 (b, 128) -> (b, 256)\n",
    "      x = self.layer_2(x)\n",
    "      x = torch.relu(x)\n",
    "\n",
    "      # layer 3 (b, 256) -> (b, 10)\n",
    "      x = self.layer_3(x)\n",
    "\n",
    "      # probability distribution over labels\n",
    "      x = torch.log_softmax(x, dim=1)\n",
    "\n",
    "      return x\n",
    "\n",
    "  def cross_entropy_loss(self, logits, labels):\n",
    "    return F.nll_loss(logits, labels)\n",
    "\n",
    "  def training_step(self, train_batch, batch_idx):\n",
    "      x, y = train_batch\n",
    "      logits = self.forward(x)\n",
    "      loss = self.cross_entropy_loss(logits, y)\n",
    "      self.log('train_loss', loss)\n",
    "      return loss\n",
    "\n",
    "\n",
    "  def validation_step(self, val_batch, batch_idx):\n",
    "      x, y = val_batch\n",
    "      logits = self.forward(x)\n",
    "      loss = self.cross_entropy_loss(logits, y)\n",
    "      self.log('val_loss', loss)\n",
    "\n",
    "  def configure_optimizers(self):\n",
    "    optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\n",
    "    return optimizer\n",
    "\n",
    "\n",
    "model = LightningMNISTClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ec0b9be",
   "metadata": {},
   "source": [
    "# train.py\n",
    "train models and save them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "134017a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "---\n",
    "---\n",
    "---\n",
    "trainer.fit(model, data_module)\n",
    "\n",
    "# Save the model with help from utils.py\n",
    "utils.save_model(model=model1,\n",
    "                 target_dir=\"models\",\n",
    "                 model_name=\"Scratch.pth\")\n",
    "utils.save_model(model=model2,\n",
    "                 target_dir=\"models\",\n",
    "                 model_name=\"ResNet-18.pth\")\n",
    "utils.save_model(model=model3,\n",
    "                 target_dir=\"models\",\n",
    "                 model_name=\"VGG-16.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59998050",
   "metadata": {},
   "source": [
    "# evaluate.py\n",
    "contains the main loop for evaluating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70d1cb63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3d731e7f",
   "metadata": {},
   "source": [
    "# search_hyperparams.py\n",
    "hyper parameter search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c96388e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ed44f43e",
   "metadata": {},
   "source": [
    "# synthesize_results.py\n",
    "An author synthesizes study data by combining the results together to enable comparison and to allow others to draw further conclusions from them"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aba26f56",
   "metadata": {},
   "source": [
    "# evaluate.py\n",
    "contains the main loop for evaluating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b82219",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0c28a1e5",
   "metadata": {},
   "source": [
    "# utils.py\n",
    "utility functions for handling hyperparams/logging/storing model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81012979",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "NUM_EPOCHS = 20\n",
    "LEARNING_RATE = 0.005\n",
    "NUM_WORKERS = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e8ce356",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Attachments",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
