{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "50907ddb-57fc-421d-b038-660803f6c94e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['All', 'Approved', 'NonApproved', 'test_set.csv', 'train_set.csv', 'valid_set.csv', 'xlbst.csv']\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision\n",
    "import random\n",
    "from torch.utils.data import DataLoader\n",
    "from PIL import Image\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "\n",
    "def set_all_seeds(seed):\n",
    "    os.environ[\"PL_GLOBAL_SEED\"] = str(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    \n",
    "# Hyperparameters\n",
    "in_channel = 3\n",
    "num_classes = 2\n",
    "learning_rate = 1e-3\n",
    "batch_size = 32\n",
    "num_epochs = 10\n",
    "random_seed = 1\n",
    "\n",
    "set_all_seeds(random_seed)\n",
    "\n",
    "# Find folder paths\n",
    "\n",
    "base_path = r\"C:/Users/kaspe/OneDrive - Aarhus Universitet/Skrivebord/BI/4. semester/Data/LBST/Danish Challenge/2023 J#/\"\n",
    "target_dirs = os.listdir(base_path)\n",
    "print(target_dirs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ce751e-64e0-4586-b91f-fd9c9af60343",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create 2 separate df's: one for Approved images, one for NonApproved, containing file_name and label\n",
    "\n",
    "# Assign label = 0 to Approved images\n",
    "approved = pd.DataFrame(data = os.listdir(os.path.join(base_path, target_dirs[1])), columns = ['file_name'])\n",
    "approved = approved.assign(label = 0)\n",
    "\n",
    "# Assign label = 1 to NonApproved images\n",
    "nonapproved = pd.DataFrame(data = os.listdir(os.path.join(base_path, target_dirs[2])), columns = ['file_name'])\n",
    "nonapproved = nonapproved.assign(label = 1)\n",
    "\n",
    "# Merge into 1 df\n",
    "df = pd.concat([approved, nonapproved])\n",
    "\n",
    "# Add parcel_id column containing character 3-10 from file_name column\n",
    "df['parcel_id'] = df['file_name'].str[3:10]\n",
    "\n",
    "# Write .csv\n",
    "df.to_csv(r'C:/Users/kaspe/OneDrive - Aarhus Universitet/Skrivebord/BI/4. semester/Data/LBST/Danish Challenge/2023 J#/xlbst.csv', sep = ',', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e50f125-25c0-4b2c-bd7f-454dcefe8bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split group by\n",
    "\n",
    "set_all_seeds(random_seed)\n",
    "\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "\n",
    "splitter = GroupShuffleSplit(test_size=0.20, n_splits=2, random_state=random_seed)\n",
    "split = splitter.split(df, groups=df.parcel_id)\n",
    "train_inds, test_inds = next(split)\n",
    "\n",
    "train_set = df.iloc[train_inds]\n",
    "test_set = df.iloc[test_inds]\n",
    "\n",
    "\n",
    "print(test_set.to_string())\n",
    "print('Test set length:',len(test_set), 'Train set length:', len(train_set), sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef860cb-52a0-4d22-a6c9-68e95b955b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split train into 80/20 train/valid\n",
    "\n",
    "train_set2 = train_set\n",
    "splitter2 = GroupShuffleSplit(test_size=0.2, n_splits =1, random_state=random_seed)\n",
    "split2 = splitter2.split(train_set2, groups=train_set2.parcel_id)\n",
    "train_inds2, valid_inds = next(split2)\n",
    "\n",
    "train_set2 = train_set.iloc[train_inds2]\n",
    "valid_set = train_set.iloc[valid_inds]\n",
    "\n",
    "# Print train, valid, test\n",
    "print(train_set.to_string())\n",
    "print(train_set2)\n",
    "print(valid_set)\n",
    "print(len(train_set), len(train_set2), len(valid_set))\n",
    "\n",
    "# Save to csv\n",
    "\n",
    "train_set2.to_csv(r'C:/Users/kaspe/OneDrive - Aarhus Universitet/Skrivebord/BI/4. semester/Data/LBST/Danish Challenge/2023 J#/train_set.csv', sep = ',', encoding='utf-8', index=False)\n",
    "valid_set.to_csv(r'C:/Users/kaspe/OneDrive - Aarhus Universitet/Skrivebord/BI/4. semester/Data/LBST/Danish Challenge/2023 J#/valid_set.csv', sep = ',', encoding='utf-8', index=False)\n",
    "test_set.to_csv(r'C:/Users/kaspe/OneDrive - Aarhus Universitet/Skrivebord/BI/4. semester/Data/LBST/Danish Challenge/2023 J#/test_set.csv', sep = ',', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bbbaf77-cf65-41a9-a3f5-8cc1b4ebccbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.youtube.com/watch?v=ZoZHd0Zm3RY&ab_channel=AladdinPersson\n",
    "\n",
    "set_all_seeds(random_seed)\n",
    "\n",
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Create PyTorch compatible datasets: From images to tensors\n",
    "\n",
    "from customDataset import LBSTDataset\n",
    "train_set = LBSTDataset(csv_file = r'C:/Users/kaspe/OneDrive - Aarhus Universitet/Skrivebord/BI/4. semester/Data/LBST/Danish Challenge/2023 J#/train_set.csv', \n",
    "                      root_dir = r'C:/Users/kaspe/OneDrive - Aarhus Universitet/Skrivebord/BI/4. semester/Data/LBST/Danish Challenge/2023 J#/All',\n",
    "                      transform = transforms.Compose([\n",
    "                                                transforms.Resize((224, 224)),\n",
    "                                                #transforms.RandomHorizontalFlip(),\n",
    "                                                #transforms.RandomResizedCrop(224),\n",
    "                                                transforms.ToTensor()#,\n",
    "                                                #transforms.Normalize()\n",
    "                      ]))\n",
    "\n",
    "valid_set = LBSTDataset(csv_file = r'C:/Users/kaspe/OneDrive - Aarhus Universitet/Skrivebord/BI/4. semester/Data/LBST/Danish Challenge/2023 J#/valid_set.csv', \n",
    "                      root_dir = r'C:/Users/kaspe/OneDrive - Aarhus Universitet/Skrivebord/BI/4. semester/Data/LBST/Danish Challenge/2023 J#/All',\n",
    "                      transform = transforms.Compose([\n",
    "                                                transforms.Resize((224, 224)),\n",
    "                                                #transforms.RandomHorizontalFlip(),\n",
    "                                                #transforms.RandomResizedCrop(224),\n",
    "                                                transforms.ToTensor()#,\n",
    "                                                #transforms.Normalize()\n",
    "                      ]))\n",
    "\n",
    "test_set = LBSTDataset(csv_file = r'C:/Users/kaspe/OneDrive - Aarhus Universitet/Skrivebord/BI/4. semester/Data/LBST/Danish Challenge/2023 J#/test_set.csv', \n",
    "                      root_dir = r'C:/Users/kaspe/OneDrive - Aarhus Universitet/Skrivebord/BI/4. semester/Data/LBST/Danish Challenge/2023 J#/All',\n",
    "                      transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor()\n",
    "]))\n",
    "\n",
    "len(train_set)\n",
    "print(train_set)\n",
    "print('The shape of tensor for 50th image in train dataset: ',train_set[49][0].shape)\n",
    "print('The label for 50th image in train dataset: ',train_set[49][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c205fe32-ad98-45ad-b0de-72f510ddc868",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_all_seeds(random_seed)\n",
    "\n",
    "# Train, valid and test loader\n",
    "\n",
    "train_loader = DataLoader(dataset=train_set,\n",
    "                          batch_size=batch_size,\n",
    "                          shuffle=True)\n",
    "\n",
    "valid_loader = DataLoader(dataset=valid_set,\n",
    "                          batch_size=batch_size,\n",
    "                          shuffle=True)\n",
    "\n",
    "test_loader = DataLoader(dataset=test_set,\n",
    "                         batch_size=batch_size,\n",
    "                         shuffle=True)\n",
    "\n",
    "# print batch of image tensor\n",
    "print('print 1st batch of image tensor:', next(iter(train_loader))[0].shape)\n",
    "print('print batch of corresponding labels:', next(iter(train_loader))[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac6c5b4c-43cf-42c9-94f2-ad8c1488411a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN(nn.Module):\n",
    "    def __init__(self, input_size, num_classes):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 50)\n",
    "        self.fc2 = nn.Linear(50, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "    \n",
    "class NN(pl.LightningModule): # pl.LightningModule inherits from nn.Module and adds extra functionality\n",
    "    def __init__(self, input_size, num_classes):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 50)\n",
    "        self.fc2 = nn.Linear(50, num_classes)\n",
    "        self.loss_fn = nn.CrossEntropyLoss()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        x = x.reshape(x.size(0), -1)\n",
    "        scores = self.forward(x) # compute scores\n",
    "        loss = F.loss_fn(scores, y) # compute losses\n",
    "        self.log('train_loss', loss)\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        x = x.reshape(x.size(0), -1)\n",
    "        scores = self.forward(x) # compute scores\n",
    "        loss = F.loss_fn(scores, y) # compute losses\n",
    "        self.log('val_loss', loss)\n",
    "        return loss\n",
    "    \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        x = x.reshape(x.size(0), -1)\n",
    "        scores = self.forward(x) # compute scores\n",
    "        loss = F.loss_fn(scores, y) # compute losses\n",
    "        self.log('test_loss', loss)\n",
    "        return loss\n",
    "    \n",
    "    def predict_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        x = x.reshape(x.size(0), -1)\n",
    "        scores = self.forward(x)\n",
    "        preds = torch.argmax(scores, dim=1)\n",
    "        return preds\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        return optim.Adam(self.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "babc847c-e88f-4b58-999d-332c4c5023a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce code length by creating a _common_step function, in order not to have to repeat code in training_step, validation_step and test_step\n",
    "\n",
    "\n",
    "class NN(pl.LightningModule): # pl.LightningModule inherits from nn.Module and adds extra functionality\n",
    "    def __init__(self, input_size, num_classes): # In the constructor, you declare all the layers you want to use.\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 50)\n",
    "        self.fc2 = nn.Linear(50, num_classes)\n",
    "        self.loss_fn = nn.CrossEntropyLoss()\n",
    "        \n",
    "    def forward(self, x): # Forward function computes output Tensors from input Tensors. In the forward function, you define how your model is going to be run, from input to output. We're accepting only a single input in here, but if you want, feel free to use more\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        loss, scores, y = self._common_step(batch, batch_idx)\n",
    "        self.log('train_loss', loss)\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        loss, scores, y = self._common_step(batch, batch_idx)\n",
    "        self.log('val_loss', loss)\n",
    "        return loss\n",
    "    \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        loss, scores, y = self._common_step(batch, batch_idx)\n",
    "        self.log('test_loss', loss)\n",
    "        return loss\n",
    "    \n",
    "    def _common_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        x = x.reshape(x.size(0), -1)\n",
    "        scores = self.forward(x)\n",
    "        loss = self.loss_fn(scores, y)\n",
    "        return loss, scores, y\n",
    "    \n",
    "    def predict_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        x = x.reshape(x.size(0), -1)\n",
    "        scores = self.forward(x)\n",
    "        preds = torch.argmax(scores, dim=1)\n",
    "        return preds\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        return optim.Adam(self.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef4b4b22-c872-4033-b5e0-5d6d73ff9786",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd5f481a-a06e-4d6d-9831-4ab5c9a3202f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
