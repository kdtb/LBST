{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2e1a4c98-53e8-4060-998d-6e252ee96995",
   "metadata": {},
   "source": [
    "## Check that CustomDataModule works\n",
    "\n",
    "The reason I want to check this is that the augmented images that i logged through tensorboard were completely off. So i wanted to make sure, that the CustomDataModule class works properly. Either it is the dataloaders not working or the images are used wrong in my model.py\n",
    "\n",
    "1. Instantiate the CustomDataModule and its .setup and .train_dataloader to be able to extract tensor batches from it\n",
    "2. Create a data variable containing images as tensors (of shape torch.Size([16, 3, 224, 224]))\n",
    "3. Convert back to actual image using ToPILImage\n",
    "4. Display it with PIL\n",
    "\n",
    "So i manually sample from my Dataset and convert the image back to an actual image, then display it with PIL\n",
    "If it displays an image you recognise then you're not loading images wrong, you might just be using them wrong in the model\n",
    "\n",
    "\n",
    "The code below only works if the dataloaders in customDataModule does not normalize the tensor.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab8f0d26-68d7-4a66-b642-726f16c55ffe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 3, 224, 224])\n",
      "torch.Size([3, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "import config\n",
    "from customDataModule import CustomDataModule\n",
    "import torchvision.transforms as T\n",
    "import torch\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "# Instantiate class\n",
    "\n",
    "dm = CustomDataModule(\n",
    "        data_dir=config.DATA_DIR,\n",
    "        train_csv=config.TRAIN_CSV,\n",
    "        val_csv=config.VAL_CSV,\n",
    "        test_csv=config.VAL_CSV,\n",
    "        batch_size=config.BATCH_SIZE,\n",
    "        num_workers=config.NUM_WORKERS,\n",
    "    )\n",
    "\n",
    "## Instantiate objects\n",
    "dm.setup(\"train\") # setup skal instantiates for at kunne lave train_dataloader\n",
    "dm.train_dataloader()\n",
    "\n",
    "# Take out the first batch of tensor images\n",
    "train_dataloader = dm.train_dataloader()\n",
    "train_dataloader_iterator = iter(train_dataloader) # Use iter() to generate an iterator for the dataloader\n",
    "data = next(train_dataloader_iterator) # use next() function on the iterator object to get 1st batch of data\n",
    "data\n",
    "print(data[0].shape)\n",
    "#data # \"data will now contain the first batch of data from train_dataloader, \n",
    "     # which may include one or multiple images depending on the batch size. If the batch size is 16, data will have the shape [16, C, H, W], where C, H, and W are the dimensions of the image in channel, height, and width, respectively.\"\n",
    "\n",
    "\n",
    "# Convert tensor to PIL image\n",
    "\n",
    "## Get first image from batch\n",
    "image_tensor = data[0][1]   # data should have shape 16: [16, C, H, W]\n",
    "print(image_tensor.shape)\n",
    "\n",
    "## define a transform to convert a tensor to PIL image\n",
    "transform = T.ToPILImage()\n",
    "\n",
    "## convert the tensor to PIL image using above transform\n",
    "image_tensor = transform(image_tensor)\n",
    "\n",
    "## display the PIL image\n",
    "\n",
    "image_tensor.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "03110d93-61db-4cda-aa0d-b6f3f8fa9199",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['All', 'Approved', 'NonApproved', 'test_set.csv', 'train_set.csv', 'val_set.csv', 'xlbst.csv']\n",
      "                                           file_name  label parcel_id\n",
      "0   22-0223605_F78EFF88702EA742E0530EEE260AEFC6.jpeg      1   0223605\n",
      "1   22-0223605_F78EFF887030A742E0530EEE260AEFC6.jpeg      1   0223605\n",
      "2   22-0223605_F78EFF88703AA742E0530EEE260AEFC6.jpeg      1   0223605\n",
      "28  22-0225160_F78EFF887012A742E0530EEE260AEFC6.jpeg      1   0225160\n",
      "29  22-0225160_F78EFF887013A742E0530EEE260AEFC6.jpeg      1   0225160\n",
      "30  22-0225160_F78EFF887014A742E0530EEE260AEFC6.jpeg      1   0225160\n",
      "31  22-0225160_F78EFF887015A742E0530EEE260AEFC6.jpeg      1   0225160\n",
      "32  22-0225160_F78EFF887016A742E0530EEE260AEFC6.jpeg      1   0225160\n",
      "33  22-0225160_F78EFF887017A742E0530EEE260AEFC6.jpeg      1   0225160\n",
      "34  22-0225160_F78EFF88701AA742E0530EEE260AEFC6.jpeg      1   0225160\n",
      "35  22-0225160_F78EFF88701BA742E0530EEE260AEFC6.jpeg      1   0225160\n",
      "36  22-0225160_F78EFF88701CA742E0530EEE260AEFC6.jpeg      1   0225160\n",
      "37  22-0225160_F78EFF88701DA742E0530EEE260AEFC6.jpeg      1   0225160\n",
      "38  22-0225160_F78EFF88701EA742E0530EEE260AEFC6.jpeg      1   0225160\n",
      "39  22-0225160_F78EFF88701FA742E0530EEE260AEFC6.jpeg      1   0225160\n",
      "Test set length:\n",
      "15\n",
      "Train set length:\n",
      "65\n"
     ]
    }
   ],
   "source": [
    "from createCSV import createCSV\n",
    "import config\n",
    "csv = createCSV(\n",
    "        base_dir = config.BASE_DIR,\n",
    "        all_csv = config.ALL_CSV,\n",
    "        train_csv = config.TRAIN_CSV,\n",
    "        val_csv = config.VAL_CSV,\n",
    "        test_csv = config.TEST_CSV,\n",
    "        label_column = config.LABEL_COLUMN,\n",
    "        test_size = config.TEST_SIZE,\n",
    "        seed = config.SEED)\n",
    "csv.set_all_seeds()\n",
    "csv.df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cd844352-810f-4eb3-b7fa-8421e2eea264",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "NN.__init__() missing 1 required positional argument: 'input_size'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 24\u001b[0m\n\u001b[0;32m     20\u001b[0m     pytorch_model \u001b[38;5;241m=\u001b[39m pytorchModel(num_classes\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mNUM_CLASSES)\n\u001b[0;32m     23\u001b[0m     logger \u001b[38;5;241m=\u001b[39m TensorBoardLogger(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtb_logs\u001b[39m\u001b[38;5;124m\"\u001b[39m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmy_model\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;66;03m# tb_logs is the folder, name is the name of the experiment/model\u001b[39;00m\n\u001b[1;32m---> 24\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mNN\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     25\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpytorch_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;43;03m#        input_size=config.IN_CHANNELS,\u001b[39;49;00m\n\u001b[0;32m     27\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_classes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mNUM_CLASSES\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     28\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLEARNING_RATE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     29\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# .to(device)\u001b[39;00m\n\u001b[0;32m     30\u001b[0m     dm \u001b[38;5;241m=\u001b[39m CustomDataModule(\n\u001b[0;32m     31\u001b[0m         data_dir\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mDATA_DIR,\n\u001b[0;32m     32\u001b[0m         train_csv\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mTRAIN_CSV,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     36\u001b[0m         num_workers\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mNUM_WORKERS,\n\u001b[0;32m     37\u001b[0m     )\n\u001b[0;32m     38\u001b[0m     trainer \u001b[38;5;241m=\u001b[39m pl\u001b[38;5;241m.\u001b[39mTrainer(\n\u001b[0;32m     39\u001b[0m         logger\u001b[38;5;241m=\u001b[39mlogger, \u001b[38;5;66;03m# PyTorch lightning will automatically know what we are logging by looking at our model.py logs\u001b[39;00m\n\u001b[0;32m     40\u001b[0m         accelerator\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mACCELERATOR,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     45\u001b[0m         callbacks\u001b[38;5;241m=\u001b[39m[MyPrintingCallback(), EarlyStopping(monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m)],\n\u001b[0;32m     46\u001b[0m     )  \u001b[38;5;66;03m# deterministic ensures random seed reproducibility\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: NN.__init__() missing 1 required positional argument: 'input_size'"
     ]
    }
   ],
   "source": [
    "# Train model\n",
    "\n",
    "from model import NN\n",
    "from customDataModule import CustomDataModule\n",
    "import config\n",
    "from callbacks import MyPrintingCallback, EarlyStopping\n",
    "import pytorch_lightning as pl\n",
    "from lightning.pytorch.loggers import TensorBoardLogger\n",
    "from lightning.pytorch import seed_everything\n",
    "from pytorchModel import pytorchModel\n",
    "\n",
    "seed_everything(\n",
    "    42, workers=True\n",
    ")  # By setting workers=True in seed_everything(), Lightning derives unique seeds across all dataloader workers and processes for torch, numpy and stdlib random number generators. When turned on, it ensures that e.g. data augmentations are not repeated across workers.\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    pytorch_model = pytorchModel(num_classes=config.NUM_CLASSES)\n",
    "    \n",
    "    \n",
    "    logger = TensorBoardLogger(\"tb_logs\", name=\"my_model\") # tb_logs is the folder, name is the name of the experiment/model\n",
    "    model = NN(\n",
    "        model=pytorch_model,\n",
    "#        input_size=config.IN_CHANNELS,\n",
    "        num_classes=config.NUM_CLASSES,\n",
    "        learning_rate=config.LEARNING_RATE,\n",
    "    )  # .to(device)\n",
    "    dm = CustomDataModule(\n",
    "        data_dir=config.DATA_DIR,\n",
    "        train_csv=config.TRAIN_CSV,\n",
    "        val_csv=config.VAL_CSV,\n",
    "        test_csv=config.VAL_CSV,\n",
    "        batch_size=config.BATCH_SIZE,\n",
    "        num_workers=config.NUM_WORKERS,\n",
    "    )\n",
    "    trainer = pl.Trainer(\n",
    "        logger=logger, # PyTorch lightning will automatically know what we are logging by looking at our model.py logs\n",
    "        accelerator=config.ACCELERATOR,\n",
    "        devices=config.DEVICES,\n",
    "        min_epochs=config.MIN_EPOCHS,\n",
    "        max_epochs=config.MAX_EPOCHS,\n",
    "        deterministic=config.DETERMINISTIC,\n",
    "        callbacks=[MyPrintingCallback(), EarlyStopping(monitor=\"val_loss\")],\n",
    "    )  # deterministic ensures random seed reproducibility\n",
    "    trainer.fit(model, dm)  # it will automatically know which dataloader to use\n",
    "    trainer.validate(model, dm)\n",
    "    trainer.test(model, dm)\n",
    "\n",
    "# A general place to start is to set num_workers equal to the number of CPU cores on that machine. You can get the number of CPU cores in python using os.cpu_count(), but note that depending on your batch size, you may overflow RAM memory.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
