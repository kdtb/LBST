{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e7300595",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "92fedcb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\kaspe'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88f00b6d",
   "metadata": {},
   "source": [
    "# data_loader.py\n",
    "specifies how the data should be fed to the network: LightningDataModule\n",
    "\n",
    "In short, data preparation has 4 steps:\n",
    "\n",
    "- Download images\n",
    "- Image transforms (these are highly subjective).\n",
    "- Generate training, validation and test dataset splits.\n",
    "- Wrap each dataset split in a DataLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fbf82a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://lightning.ai/docs/pytorch/latest/data/datamodule.html\n",
    "\n",
    "import lightning.pytorch as pl\n",
    "from torch.utils.data import random_split, DataLoader\n",
    "\n",
    "# Note - you must have torchvision installed for this example\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision import transforms\n",
    "\n",
    "\n",
    "class MNISTDataModule(pl.LightningDataModule):\n",
    "    def __init__(self, data_dir: str = \"./\"):\n",
    "        super().__init__()\n",
    "        self.data_dir = data_dir\n",
    "        self.transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])\n",
    "\n",
    "    def prepare_data(self):\n",
    "        # download\n",
    "        MNIST(self.data_dir, train=True, download=True)\n",
    "        MNIST(self.data_dir, train=False, download=True)\n",
    "\n",
    "    def setup(self, stage: str):\n",
    "        # Assign train/val datasets for use in dataloaders\n",
    "        if stage == \"fit\":\n",
    "            mnist_full = MNIST(self.data_dir, train=True, transform=self.transform)\n",
    "            self.mnist_train, self.mnist_val = random_split(mnist_full, [55000, 5000])\n",
    "\n",
    "        # Assign test dataset for use in dataloader(s)\n",
    "        if stage == \"test\":\n",
    "            self.mnist_test = MNIST(self.data_dir, train=False, transform=self.transform)\n",
    "\n",
    "        if stage == \"predict\":\n",
    "            self.mnist_predict = MNIST(self.data_dir, train=False, transform=self.transform)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.mnist_train, batch_size=32)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.mnist_val, batch_size=32)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.mnist_test, batch_size=32)\n",
    "\n",
    "    def predict_dataloader(self):\n",
    "        return DataLoader(self.mnist_predict, batch_size=32)\n",
    "\n",
    "data_module = MNISTDataModule()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceb11905",
   "metadata": {},
   "source": [
    "# model.py\n",
    "specifies the neural network architecture, the loss function and evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a969db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import pytorch_lightning as pl\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torch.nn import functional as F\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision import datasets, transforms\n",
    "import os\n",
    "\n",
    "class LightningMNISTClassifier(pl.LightningModule):\n",
    "\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "\n",
    "    # mnist images are (1, 28, 28) (channels, width, height) \n",
    "    self.layer_1 = torch.nn.Linear(28 * 28, 128)\n",
    "    self.layer_2 = torch.nn.Linear(128, 256)\n",
    "    self.layer_3 = torch.nn.Linear(256, 10)\n",
    "\n",
    "  def forward(self, x):\n",
    "      batch_size, channels, width, height = x.size()\n",
    "\n",
    "      # (b, 1, 28, 28) -> (b, 1*28*28)\n",
    "      x = x.view(batch_size, -1)\n",
    "\n",
    "      # layer 1 (b, 1*28*28) -> (b, 128)\n",
    "      x = self.layer_1(x)\n",
    "      x = torch.relu(x)\n",
    "\n",
    "      # layer 2 (b, 128) -> (b, 256)\n",
    "      x = self.layer_2(x)\n",
    "      x = torch.relu(x)\n",
    "\n",
    "      # layer 3 (b, 256) -> (b, 10)\n",
    "      x = self.layer_3(x)\n",
    "\n",
    "      # probability distribution over labels\n",
    "      x = torch.log_softmax(x, dim=1)\n",
    "\n",
    "      return x\n",
    "\n",
    "  def cross_entropy_loss(self, logits, labels):\n",
    "    return F.nll_loss(logits, labels)\n",
    "\n",
    "  def training_step(self, train_batch, batch_idx):\n",
    "      x, y = train_batch\n",
    "      logits = self.forward(x)\n",
    "      loss = self.cross_entropy_loss(logits, y)\n",
    "      self.log('train_loss', loss)\n",
    "      return loss\n",
    "\n",
    "\n",
    "  def validation_step(self, val_batch, batch_idx):\n",
    "      x, y = val_batch\n",
    "      logits = self.forward(x)\n",
    "      loss = self.cross_entropy_loss(logits, y)\n",
    "      self.log('val_loss', loss)\n",
    "\n",
    "  def configure_optimizers(self):\n",
    "    optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\n",
    "    return optimizer\n",
    "\n",
    "\n",
    "model = LightningMNISTClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ec0b9be",
   "metadata": {},
   "source": [
    "# train.py\n",
    "train models and save them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "134017a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "---\n",
    "---\n",
    "---\n",
    "trainer.fit(model, data_module)\n",
    "\n",
    "# Save the model with help from utils.py\n",
    "utils.save_model(model=model1,\n",
    "                 target_dir=\"models\",\n",
    "                 model_name=\"Scratch.pth\")\n",
    "utils.save_model(model=model2,\n",
    "                 target_dir=\"models\",\n",
    "                 model_name=\"ResNet-18.pth\")\n",
    "utils.save_model(model=model3,\n",
    "                 target_dir=\"models\",\n",
    "                 model_name=\"VGG-16.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59998050",
   "metadata": {},
   "source": [
    "# evaluate.py\n",
    "contains the main loop for evaluating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70d1cb63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3d731e7f",
   "metadata": {},
   "source": [
    "# search_hyperparams.py\n",
    "hyper parameter search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c96388e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ed44f43e",
   "metadata": {},
   "source": [
    "# synthesize_results.py\n",
    "An author synthesizes study data by combining the results together to enable comparison and to allow others to draw further conclusions from them"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aba26f56",
   "metadata": {},
   "source": [
    "# evaluate.py\n",
    "contains the main loop for evaluating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b82219",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0c28a1e5",
   "metadata": {},
   "source": [
    "# utils.py\n",
    "utility functions for handling hyperparams/logging/storing model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81012979",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "NUM_EPOCHS = 20\n",
    "LEARNING_RATE = 0.005\n",
    "NUM_WORKERS = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e8ce356",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Attachments",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
